from ultralytics import YOLO
import easyocr
import cv2
import os
import numpy as np

# Initialize YOLO model
model = YOLO("best.pt")

# Initialize EasyOCR reader
reader = easyocr.Reader(['en'])

# Source image
source = "bien2.jpg"

# Check if source image exists
if not os.path.exists(source):
    print(f"Kh√¥ng t√¨m th·∫•y ·∫£nh: {source}")
    print("C√°c ·∫£nh c√≥ s·∫µn:")
    for file in os.listdir("."):
        if file.lower().endswith(('.jpg', '.jpeg', '.png', '.jfif', '.webp')):
            print(f"  - {file}")
    exit(1)

print(f"ƒêang x·ª≠ l√Ω ·∫£nh: {source}")

# Load the image
image = cv2.imread(source)
if image is None:
    print(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {source}")
    exit(1)

# Start prediction (ch·ªâ ch·∫°y m·ªôt l·∫ßn)
print("ƒêang nh·∫≠n di·ªán bi·ªÉn s·ªë xe...")
results = model.predict(source=image, show=False)  # Kh√¥ng hi·ªÉn th·ªã trong qu√° tr√¨nh predict

# Process results
detected_text = "Kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë"
for result in results:
    boxes = result.boxes.xyxy  # Bounding box coordinates (x1, y1, x2, y2)
    confidences = result.boxes.conf  # Confidence scores
    
    if len(boxes) == 0:
        print("Kh√¥ng t√¨m th·∫•y bi·ªÉn s·ªë xe trong ·∫£nh")
        continue
        
    for i, (box, confidence) in enumerate(zip(boxes, confidences)):
        if confidence > 0.25:  # Ensure the detection is confident enough
            x1, y1, x2, y2 = map(int, box)
            print(f"Ph√°t hi·ªán bi·ªÉn s·ªë #{i+1} v·ªõi ƒë·ªô tin c·∫≠y: {confidence:.2f}")
            
            # Crop the detected license plate area
            cropped_plate = image[y1:y2, x1:x2]
            
            # L∆∞u ·∫£nh g·ªëc crop ƒë·ªÉ ki·ªÉm tra
            cv2.imwrite(f"cropped_plate_{i+1}_original.jpg", cropped_plate)
            
            # Preprocessing ƒë·ªÉ kh·∫Øc ph·ª•c d√® ch·ªØ
            # 1. Gi·ªØ nguy√™n t·ª∑ l·ªá khung h√¨nh
            height, width = cropped_plate.shape[:2]
            
            # 2. TƒÉng k√≠ch th∆∞·ªõc ·∫£nh ƒë·ªÉ d·ªÖ ƒë·ªçc h∆°n (gi·ªØ t·ª∑ l·ªá)
            scale_factor = 3
            new_width = width * scale_factor
            new_height = height * scale_factor
            
            # 3. Resize v·ªõi interpolation t·ªët h∆°n
            resized_plate = cv2.resize(cropped_plate, (new_width, new_height), 
                                     interpolation=cv2.INTER_CUBIC)
            
            # 4. L√†m m·ªãn ·∫£nh ƒë·ªÉ gi·∫£m nhi·ªÖu
            smoothed_plate = cv2.GaussianBlur(resized_plate, (3, 3), 0)
            
            # 5. TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n
            lab = cv2.cvtColor(smoothed_plate, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            cl = clahe.apply(l)
            enhanced = cv2.merge((cl,a,b))
            enhanced_plate = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
            
            # L∆∞u ·∫£nh ƒë√£ x·ª≠ l√Ω ƒë·ªÉ ki·ªÉm tra
            cv2.imwrite(f"cropped_plate_{i+1}_enhanced.jpg", enhanced_plate)
            
            # 6. Th·ª≠ OCR v·ªõi ·∫£nh g·ªëc tr∆∞·ªõc
            print("  ƒêang ƒë·ªçc v·ªõi ·∫£nh g·ªëc...")
            text_results_original = reader.readtext(cropped_plate)
            
            # 7. Th·ª≠ OCR v·ªõi ·∫£nh ƒë√£ x·ª≠ l√Ω
            print("  ƒêang ƒë·ªçc v·ªõi ·∫£nh ƒë√£ x·ª≠ l√Ω...")
            text_results_enhanced = reader.readtext(enhanced_plate)
            
            # K·∫øt h·ª£p k·∫øt qu·∫£ t·ª´ c·∫£ hai ph∆∞∆°ng ph√°p
            all_text_results = text_results_original + text_results_enhanced
            
            # Extract and print the detected text
            if all_text_results:
                print(f"  T√¨m th·∫•y {len(all_text_results)} k·∫øt qu·∫£ OCR:")
                
                # T√°ch c√°c ph·∫ßn text v√† s·∫Øp x·∫øp theo v·ªã tr√≠ Y (t·ª´ tr√™n xu·ªëng d∆∞·ªõi)
                text_with_positions = []
                for (bbox, text, prob) in all_text_results:
                    if prob > 0.2:  # Gi·∫£m threshold ƒë·ªÉ l·∫•y nhi·ªÅu text h∆°n
                        # T√≠nh v·ªã tr√≠ Y trung b√¨nh c·ªßa text
                        y_pos = np.mean([point[1] for point in bbox])
                        text_with_positions.append((text, prob, y_pos))
                
                # S·∫Øp x·∫øp theo v·ªã tr√≠ Y (t·ª´ tr√™n xu·ªëng d∆∞·ªõi)
                text_with_positions.sort(key=lambda x: x[2])
                
                # K·∫øt h·ª£p c√°c text th√†nh bi·ªÉn s·ªë ho√†n ch·ªânh
                if len(text_with_positions) >= 2:
                    # L·∫•y 2 text ƒë·∫ßu ti√™n (d√≤ng tr√™n v√† d√≤ng d∆∞·ªõi)
                    top_text = text_with_positions[0][0]
                    bottom_text = text_with_positions[1][0]
                    
                    # K·∫øt h·ª£p th√†nh bi·ªÉn s·ªë ho√†n ch·ªânh
                    full_plate = f"{top_text} {bottom_text}"
                    
                    detected_text = full_plate
                    print(f"  ‚Üí Bi·ªÉn s·ªë ho√†n ch·ªânh: '{full_plate}'")
                    
                    # Draw the bounding box and text on the image
                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(image, full_plate, (x1, y1 - 10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                elif len(text_with_positions) == 1:
                    # Ch·ªâ c√≥ 1 text
                    single_text = text_with_positions[0][0]
                    detected_text = single_text
                    print(f"  ‚Üí Ch·ªâ t√¨m th·∫•y 1 d√≤ng: '{single_text}'")
                    
                    # Draw the bounding box and text on the image
                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(image, single_text, (x1, y1 - 10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                else:
                    print("  ‚Üí Kh√¥ng c√≥ k·∫øt qu·∫£ ƒë·ªß tin c·∫≠y")
                    # Still draw the bounding box
                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)
                    cv2.putText(image, "No text", (x1, y1 - 10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                print("  Kh√¥ng th·ªÉ ƒë·ªçc vƒÉn b·∫£n t·ª´ bi·ªÉn s·ªë")
                # Still draw the bounding box
                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)
                cv2.putText(image, "No text", (x1, y1 - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

# Save the result image
output_filename = "result_detection.jpg"
cv2.imwrite(output_filename, image)
print(f"\nK·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {output_filename}")

# Hi·ªÉn th·ªã ·∫£nh k·∫øt qu·∫£ (ch·ªâ m·ªôt l·∫ßn)
try:
    cv2.imshow("License Plate Detection Result", image)
    print("Nh·∫•n ph√≠m 'q' ƒë·ªÉ ƒë√≥ng c·ª≠a s·ªï...")
    
    # Ch·ªù ng∆∞·ªùi d√πng nh·∫•n ph√≠m 'q' ƒë·ªÉ tho√°t
    while True:
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
    
    cv2.destroyAllWindows()
    print("ƒê√£ ƒë√≥ng c·ª≠a s·ªï hi·ªÉn th·ªã")
    
except Exception as e:
    print(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã c·ª≠a s·ªï: {e}")
    print("·∫¢nh k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u, b·∫°n c√≥ th·ªÉ m·ªü ƒë·ªÉ xem")

print(f"\nüéØ K·∫øt qu·∫£ cu·ªëi c√πng: {detected_text}")
print("Ho√†n th√†nh nh·∫≠n di·ªán bi·ªÉn s·ªë xe!")
print("B·∫°n c√≥ th·ªÉ m·ªü file 'result_detection.jpg' ƒë·ªÉ xem k·∫øt qu·∫£!")
print("\nüìÅ C√°c file ·∫£nh crop ƒë√£ ƒë∆∞·ª£c l∆∞u:")
print("  - cropped_plate_1_original.jpg: ·∫¢nh crop g·ªëc")
print("  - cropped_plate_1_enhanced.jpg: ·∫¢nh ƒë√£ x·ª≠ l√Ω")

